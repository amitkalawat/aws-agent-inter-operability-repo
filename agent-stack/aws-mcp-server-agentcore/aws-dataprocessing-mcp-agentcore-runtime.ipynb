{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Data Processing MCP Server on AgentCore Runtime\n",
    "\n",
    "This notebook demonstrates how to test and deploy the AWS Data Processing MCP server to Amazon Bedrock AgentCore Runtime.\n",
    "\n",
    "## Prerequisites Setup\n",
    "\n",
    "**Step 1:** Clone the AWS MCP repository\n",
    "```bash\n",
    "git clone https://github.com/awslabs/mcp.git\n",
    "```\n",
    "\n",
    "**Step 2:** Copy the AWS Data Processing MCP server to your project root\n",
    "```bash\n",
    "cp -r ./mcp/src/aws-dataprocessing-mcp-server ./\n",
    "```\n",
    "\n",
    "**Step 3:** Set up your environment variables in `.env` file:\n",
    "```\n",
    "COGNITO_POOL_ID=your_pool_id\n",
    "COGNITO_REGION=us-east-1\n",
    "COGNITO_USERNAME=admin\n",
    "COGNITO_CLIENT_SECRET=your_client_secret\n",
    "COGNITO_PASSWORD=your_password\n",
    "AWS_PROFILE=default\n",
    "AWS_REGION=us-east-1\n",
    "CUSTOM_TAGS=false\n",
    "```\n",
    "\n",
    "**Step 4:** Follow the instructions below to complete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Data Processing MCP Server Overview\n",
    "\n",
    "The AWS Data Processing MCP server provides comprehensive data processing tools and real-time pipeline visibility across AWS Glue, Amazon EMR-EC2, and Amazon Athena. This integration equips AI assistants with 40+ specialized tools organized into 14 handler classes:\n",
    "\n",
    "### AWS Glue Integration (20+ tools)\n",
    "\n",
    "#### Data Catalog Management\n",
    "- **`manage_aws_glue_databases`**: Create, update, delete, and list Glue databases\n",
    "- **`manage_aws_glue_tables`**: Manage tables with schema definition and partitioning\n",
    "- **`manage_aws_glue_connections`**: Configure connections to external data sources\n",
    "- **`manage_aws_glue_partitions`**: Handle table partitions for optimized querying\n",
    "- **`manage_aws_glue_catalog`**: Import and manage external catalogs\n",
    "\n",
    "#### ETL Job Orchestration\n",
    "- **`manage_aws_glue_jobs`**: Create, run, monitor, and manage Glue ETL jobs\n",
    "- **`manage_aws_glue_crawlers`**: Automated data discovery and cataloging\n",
    "- **`manage_aws_glue_classifiers`**: Custom data format detection\n",
    "\n",
    "#### Interactive Development\n",
    "- **`manage_aws_glue_sessions`**: Interactive Spark and Ray workloads\n",
    "- **`manage_aws_glue_statements`**: Execute code in interactive sessions\n",
    "\n",
    "#### Workflow Management\n",
    "- **`manage_aws_glue_workflows`**: Orchestrate complex ETL activities\n",
    "- **`manage_aws_glue_triggers`**: Schedule and automate workflow execution\n",
    "\n",
    "#### Security and Configuration\n",
    "- **`manage_aws_glue_usage_profiles`**: Resource allocation and cost management\n",
    "- **`manage_aws_glue_security_configurations`**: Data encryption settings\n",
    "- **`manage_aws_glue_encryption`**: Catalog encryption management\n",
    "- **`manage_aws_glue_resource_policies`**: Access control policies\n",
    "\n",
    "### Amazon EMR Integration (10+ tools)\n",
    "\n",
    "#### Cluster Management\n",
    "- **`manage_aws_emr_clusters`**: Create, configure, monitor, and terminate EMR clusters\n",
    "- **`manage_aws_emr_ec2_instances`**: Manage instance fleets and groups with auto-scaling\n",
    "- **`manage_aws_emr_ec2_steps`**: Submit and monitor Hadoop, Spark, and other job steps\n",
    "\n",
    "### Amazon Athena Integration (10+ tools)\n",
    "\n",
    "#### Query Management\n",
    "- **`manage_aws_athena_query_executions`**: Execute, monitor, and manage SQL queries\n",
    "- **`manage_aws_athena_named_queries`**: Create reusable query libraries\n",
    "\n",
    "#### Data Catalog Operations\n",
    "- **`manage_aws_athena_data_catalogs`**: Manage multiple catalog types (LAMBDA, GLUE, HIVE, FEDERATED)\n",
    "- **`manage_aws_athena_databases_and_tables`**: Database and table metadata discovery\n",
    "- **`manage_aws_athena_workgroups`**: Cost control and access management\n",
    "\n",
    "### Common Resource Management\n",
    "\n",
    "#### IAM and S3 Tools\n",
    "- **`add_inline_policy`**: Create custom IAM policies for data processing services\n",
    "- **`get_policies_for_role`**: Retrieve role permissions\n",
    "- **`create_data_processing_role`**: Create specialized IAM roles\n",
    "- **`get_roles_for_service`**: Find service-specific roles\n",
    "- **`list_s3_buckets`**: Analyze S3 bucket usage for data processing\n",
    "- **`upload_to_s3`**: Upload scripts and code to S3\n",
    "- **`analyze_s3_usage_for_data_processing`**: Usage pattern analysis\n",
    "\n",
    "### Key Features\n",
    "- **Read/Write Modes**: Optional `--allow-write` flag for mutating operations\n",
    "- **Sensitive Data Access**: `--allow-sensitive-data-access` for logs and events\n",
    "- **Resource Tagging**: MCP-managed resource tracking with optional `CUSTOM_TAGS` override\n",
    "- **Multi-Service Integration**: Seamless workflows across Glue, EMR, and Athena\n",
    "- **Natural Language Interface**: Complex data operations through conversational AI\n",
    "\n",
    "All tools require appropriate AWS permissions and work together to provide end-to-end data processing pipeline management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "### System Requirements\n",
    "- Python 3.10 or higher\n",
    "- AWS CLI configured with valid credentials\n",
    "- Docker installed (for containerization)\n",
    "\n",
    "### AWS Permissions\n",
    "Your AWS credentials must have comprehensive permissions for:\n",
    "\n",
    "#### Required for All Operations\n",
    "- Amazon Bedrock AgentCore\n",
    "- Amazon ECR (for container registry)\n",
    "- Amazon Cognito (for authentication)\n",
    "- IAM (for role creation)\n",
    "- AWS Systems Manager Parameter Store\n",
    "- AWS Secrets Manager\n",
    "\n",
    "#### Data Processing Services\n",
    "- **AWS Glue**: Full access for data catalog, ETL jobs, crawlers, interactive sessions\n",
    "- **Amazon EMR**: Cluster management, instance operations, step execution\n",
    "- **Amazon Athena**: Query execution, workgroup management, data catalog operations\n",
    "- **Amazon S3**: Data storage and script hosting\n",
    "- **CloudWatch**: Logging and monitoring\n",
    "\n",
    "**Security Note**: This MCP server requires extensive permissions for comprehensive data processing operations. Use appropriate access controls in production environments.\n",
    "\n",
    "### Project Structure\n",
    "- `aws-dataprocessing-mcp-server/` - The MCP server implementation\n",
    "- `dataprocessing-requirements.txt` - Python dependencies for data processing\n",
    "- `utils.py` - Helper functions for Cognito and IAM setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install all required Python packages using uv (recommended) or pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Profile set to: ibc2025\n"
     ]
    }
   ],
   "source": [
    "# Configure AWS Profile\n",
    "import os\n",
    "os.environ['AWS_PROFILE'] = 'ibc2025'\n",
    "print(f\"AWS Profile set to: {os.environ['AWS_PROFILE']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/homebrew/opt/python@3.11/bin/python3.11\n",
      "Requirement already satisfied: mcp>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (1.13.0)\n",
      "Requirement already satisfied: pydantic>=2.10.6 in /opt/homebrew/lib/python3.11/site-packages (from -r dataprocessing-requirements.txt (line 3)) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/homebrew/lib/python3.11/site-packages (from -r dataprocessing-requirements.txt (line 4)) (4.14.1)\n",
      "Requirement already satisfied: boto3>=1.34.0 in /opt/homebrew/lib/python3.11/site-packages (from -r dataprocessing-requirements.txt (line 7)) (1.40.15)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/homebrew/lib/python3.11/site-packages (from -r dataprocessing-requirements.txt (line 8)) (2.32.5)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /opt/homebrew/lib/python3.11/site-packages (from -r dataprocessing-requirements.txt (line 11)) (6.0.2)\n",
      "Requirement already satisfied: cachetools>=5.3.0 in /opt/homebrew/lib/python3.11/site-packages (from -r dataprocessing-requirements.txt (line 12)) (6.1.0)\n",
      "Requirement already satisfied: loguru>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from -r dataprocessing-requirements.txt (line 15)) (0.7.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.11/site-packages (from -r dataprocessing-requirements.txt (line 18)) (1.1.1)\n",
      "Requirement already satisfied: bedrock-agentcore-starter-toolkit>=0.1.3 in /opt/homebrew/lib/python3.11/site-packages (from -r dataprocessing-requirements.txt (line 19)) (0.1.6)\n",
      "Requirement already satisfied: anyio>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (4.10.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /opt/homebrew/lib/python3.11/site-packages (from mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.27.1 in /opt/homebrew/lib/python3.11/site-packages (from mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /opt/homebrew/lib/python3.11/site-packages (from mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /opt/homebrew/lib/python3.11/site-packages (from mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/homebrew/lib/python3.11/site-packages (from mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /opt/homebrew/lib/python3.11/site-packages (from mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in /opt/homebrew/lib/python3.11/site-packages (from mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (0.47.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /opt/homebrew/lib/python3.11/site-packages (from mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (0.35.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.10.6->-r dataprocessing-requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.10.6->-r dataprocessing-requirements.txt (line 3)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.10.6->-r dataprocessing-requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.15 in /opt/homebrew/lib/python3.11/site-packages (from boto3>=1.34.0->-r dataprocessing-requirements.txt (line 7)) (1.40.15)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/homebrew/lib/python3.11/site-packages (from boto3>=1.34.0->-r dataprocessing-requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/homebrew/lib/python3.11/site-packages (from boto3>=1.34.0->-r dataprocessing-requirements.txt (line 7)) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/homebrew/lib/python3.11/site-packages (from botocore<1.41.0,>=1.40.15->boto3>=1.34.0->-r dataprocessing-requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/homebrew/lib/python3.11/site-packages (from botocore<1.41.0,>=1.40.15->boto3>=1.34.0->-r dataprocessing-requirements.txt (line 7)) (1.26.20)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.15->boto3>=1.34.0->-r dataprocessing-requirements.txt (line 7)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31.0->-r dataprocessing-requirements.txt (line 8)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31.0->-r dataprocessing-requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31.0->-r dataprocessing-requirements.txt (line 8)) (2025.8.3)\n",
      "Requirement already satisfied: autopep8>=2.3.2 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (2.3.2)\n",
      "Requirement already satisfied: bedrock-agentcore>=0.1.2 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.1.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.17.0)\n",
      "Requirement already satisfied: jinja2>=3.1.6 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (3.1.6)\n",
      "Requirement already satisfied: openapi-spec-validator>=0.7.2 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.7.2)\n",
      "Requirement already satisfied: prance>=25.4.8.0 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (25.4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.51 in /Users/dohtem/Library/Python/3.11/lib/python/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (3.0.51)\n",
      "Requirement already satisfied: py-openapi-schema-to-json-schema>=0.0.3 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.0.3)\n",
      "Requirement already satisfied: questionary>=2.1.0 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (2.1.0)\n",
      "Requirement already satisfied: rich>=13.0.0 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (14.1.0)\n",
      "Requirement already satisfied: ruamel-yaml>=0.18.14 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.18.15)\n",
      "Requirement already satisfied: toml>=0.10.2 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.10.2)\n",
      "Requirement already satisfied: typer>=0.16.0 in /opt/homebrew/lib/python3.11/site-packages (from bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.16.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.11/site-packages (from anyio>=4.5->mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: pycodestyle>=2.12.0 in /opt/homebrew/lib/python3.11/site-packages (from autopep8>=2.3.2->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (2.14.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx>=0.27.1->mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2>=3.1.6->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp>=1.11.0->mcp[cli]>=1.11.0->-r dataprocessing-requirements.txt (line 2)) (0.27.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.3.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /opt/homebrew/lib/python3.11/site-packages (from openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (1.11.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.6.3)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.4.4)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/homebrew/lib/python3.11/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.1.4)\n",
      "Requirement already satisfied: chardet>=5.2 in /opt/homebrew/lib/python3.11/site-packages (from prance>=25.4.8.0->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (5.2.0)\n",
      "Requirement already satisfied: packaging>=24.2 in /Users/dohtem/Library/Python/3.11/lib/python/site-packages (from prance>=25.4.8.0->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (25.0)\n",
      "Requirement already satisfied: wcwidth in /Users/dohtem/Library/Python/3.11/lib/python/site-packages (from prompt-toolkit>=3.0.51->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.11/site-packages (from rich>=13.0.0->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/dohtem/Library/Python/3.11/lib/python/site-packages (from rich>=13.0.0->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.0.0->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.1.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/homebrew/lib/python3.11/site-packages (from ruamel-yaml>=0.18.14->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (0.2.12)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/lib/python3.11/site-packages (from typer>=0.16.0->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typer>=0.16.0->bedrock-agentcore-starter-toolkit>=0.1.3->-r dataprocessing-requirements.txt (line 19)) (1.5.4)\n",
      "✓ All packages installed successfully\n",
      "✓ boto3 available\n",
      "✓ python-dotenv available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check current Python and install packages directly\n",
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Install packages using the current Python interpreter\n",
    "import subprocess\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"dataprocessing-requirements.txt\"])\n",
    "    print(\"✓ All packages installed successfully\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error installing packages: {e}\")\n",
    "    \n",
    "# Verify key packages are available\n",
    "try:\n",
    "    import boto3\n",
    "    print(\"✓ boto3 available\")\n",
    "except ImportError:\n",
    "    print(\"❌ boto3 not available\")\n",
    "    \n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    print(\"✓ python-dotenv available\")\n",
    "except ImportError:\n",
    "    print(\"❌ python-dotenv not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Profile set to: ibc2025\n"
     ]
    }
   ],
   "source": [
    "# Configure AWS Profile\n",
    "import os\n",
    "os.environ['AWS_PROFILE'] = 'ibc2025'\n",
    "print(f\"AWS Profile set to: {os.environ['AWS_PROFILE']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m10 packages\u001b[0m \u001b[2min 31ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install -r dataprocessing-requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Local Testing\n",
    "\n",
    "Before deploying to AgentCore Runtime, let's test the AWS Data Processing MCP server locally.\n",
    "\n",
    "### 2.1 MCP Server Wrapper\n",
    "\n",
    "The `mcp-server.py` file creates a FastMCP wrapper around the AWS Data Processing MCP server for AgentCore deployment. This wrapper:\n",
    "\n",
    "- Imports all 14 handler classes from the original server implementation\n",
    "- Registers 40+ tools across Glue, EMR, and Athena services\n",
    "- Configures the server for HTTP transport on port 8000\n",
    "- Supports `--allow-write` and `--allow-sensitive-data-access` flags\n",
    "- Enables stateless HTTP mode for AgentCore compatibility\n",
    "- Provides comprehensive instructions for data processing workflows\n",
    "\n",
    "The server exposes tools from these handler classes:\n",
    "- **Glue Handlers**: Data Catalog, ETL Jobs, Crawlers, Interactive Sessions, Workflows, Commons\n",
    "- **EMR Handlers**: Clusters, Instances, Steps\n",
    "- **Athena Handlers**: Queries, Data Catalogs, Workgroups\n",
    "- **Common Handlers**: IAM and S3 resource management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp-server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp-server.py\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "# Add the path before any imports\n",
    "sys.path.insert(0, os.path.abspath(\"./aws-dataprocessing-mcp-server\"))\n",
    "\n",
    "# Import all handler classes from the original server\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.athena.athena_data_catalog_handler import AthenaDataCatalogHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.athena.athena_query_handler import AthenaQueryHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.athena.athena_workgroup_handler import AthenaWorkGroupHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.commons.common_resource_handler import CommonResourceHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.emr.emr_ec2_cluster_handler import EMREc2ClusterHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.emr.emr_ec2_instance_handler import EMREc2InstanceHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.emr.emr_ec2_steps_handler import EMREc2StepsHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.glue.crawler_handler import CrawlerHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.glue.data_catalog_handler import GlueDataCatalogHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.glue.glue_commons_handler import GlueCommonsHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.glue.glue_etl_handler import GlueEtlJobsHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.glue.interactive_sessions_handler import GlueInteractiveSessionsHandler\n",
    "from awslabs.aws_dataprocessing_mcp_server.handlers.glue.worklows_handler import GlueWorkflowAndTriggerHandler\n",
    "\n",
    "# Create a new FastMCP instance with correct parameters\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# Parse command line arguments\n",
    "parser = argparse.ArgumentParser(description='AWS Data Processing MCP Server')\n",
    "parser.add_argument('--allow-write', action='store_true', help='Enable write operations')\n",
    "parser.add_argument('--allow-sensitive-data-access', action='store_true', help='Allow access to sensitive data')\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "# Store flags in environment variables for handlers\n",
    "if args.allow_write:\n",
    "    os.environ['ALLOW_WRITE'] = 'true'\n",
    "if args.allow_sensitive_data_access:\n",
    "    os.environ['ALLOW_SENSITIVE_DATA_ACCESS'] = 'true'\n",
    "\n",
    "mcp = FastMCP(\n",
    "    'awslabs.aws-dataprocessing-mcp-server',\n",
    "    host=\"0.0.0.0\",\n",
    "    stateless_http=True,\n",
    "    instructions=\"\"\"AWS Data Processing MCP Server provides comprehensive tools for managing AWS data processing services including Glue, EMR, and Athena.\n",
    "\n",
    "    This server enables you to:\n",
    "    - Manage AWS Glue Data Catalog with databases, tables, connections, and partitions\n",
    "    - Create and orchestrate ETL jobs with automated crawlers and interactive sessions\n",
    "    - Deploy and manage Amazon EMR clusters with instance fleet management\n",
    "    - Execute and monitor Hadoop, Spark, and other big data processing steps\n",
    "    - Run SQL queries through Amazon Athena with workgroup management\n",
    "    - Configure security, encryption, and access policies across all services\n",
    "    - Manage IAM roles and S3 resources for data processing workflows\n",
    "\n",
    "    ## Available Tool Categories:\n",
    "    \n",
    "    ### AWS Glue Tools (20+ tools)\n",
    "    - **Data Catalog**: manage_aws_glue_databases, manage_aws_glue_tables, manage_aws_glue_connections, manage_aws_glue_partitions, manage_aws_glue_catalog\n",
    "    - **ETL Jobs**: manage_aws_glue_jobs (create, run, monitor job runs, bookmarks)\n",
    "    - **Crawlers**: manage_aws_glue_crawlers, manage_aws_glue_classifiers\n",
    "    - **Interactive Sessions**: manage_aws_glue_sessions, manage_aws_glue_statements\n",
    "    - **Workflows**: manage_aws_glue_workflows, manage_aws_glue_triggers\n",
    "    - **Security & Config**: manage_aws_glue_usage_profiles, manage_aws_glue_security_configurations, manage_aws_glue_encryption, manage_aws_glue_resource_policies\n",
    "    \n",
    "    ### Amazon EMR Tools (10+ tools)\n",
    "    - **Cluster Management**: manage_aws_emr_clusters (create, configure, terminate clusters)\n",
    "    - **Instance Management**: manage_aws_emr_ec2_instances (fleet and group management)\n",
    "    - **Step Execution**: manage_aws_emr_ec2_steps (submit and monitor jobs)\n",
    "    \n",
    "    ### Amazon Athena Tools (10+ tools)\n",
    "    - **Query Execution**: manage_aws_athena_query_executions (execute, monitor SQL queries)\n",
    "    - **Named Queries**: manage_aws_athena_named_queries (reusable query libraries)\n",
    "    - **Data Catalogs**: manage_aws_athena_data_catalogs (LAMBDA, GLUE, HIVE, FEDERATED)\n",
    "    - **Discovery**: manage_aws_athena_databases_and_tables (metadata exploration)\n",
    "    - **Workgroups**: manage_aws_athena_workgroups (cost control, access management)\n",
    "    \n",
    "    ### Common Resource Tools\n",
    "    - **IAM Management**: add_inline_policy, get_policies_for_role, create_data_processing_role, get_roles_for_service\n",
    "    - **S3 Operations**: list_s3_buckets, upload_to_s3, analyze_s3_usage_for_data_processing\n",
    "\n",
    "    ## Operation Modes:\n",
    "    - **Read-Only Mode** (default): Safe exploration and monitoring operations\n",
    "    - **Write Mode** (--allow-write): Enable resource creation, modification, and deletion\n",
    "    - **Sensitive Data Access** (--allow-sensitive-data-access): Access logs, events, and sensitive configurations\n",
    "\n",
    "    ## Common Workflows:\n",
    "    1. **Data Discovery**: Create crawlers → Generate tables → Query with Athena\n",
    "    2. **ETL Pipeline**: Design Glue jobs → Configure workflows → Monitor execution\n",
    "    3. **Big Data Processing**: Launch EMR clusters → Submit steps → Process at scale\n",
    "    4. **Analytics**: Set up Athena workgroups → Execute queries → Analyze results\n",
    "\n",
    "    ## Resource Management:\n",
    "    - All resources are tagged for MCP management (unless CUSTOM_TAGS=true)\n",
    "    - Only MCP-created resources can be modified or deleted through this server\n",
    "    - IAM roles and policies are automatically configured for service access\n",
    "\n",
    "    For more information about AWS Data Processing services, visit:\n",
    "    - AWS Glue: https://aws.amazon.com/glue/\n",
    "    - Amazon EMR: https://aws.amazon.com/emr/\n",
    "    - Amazon Athena: https://aws.amazon.com/athena/\n",
    "    \"\"\",\n",
    "    dependencies=[\n",
    "        'pydantic',\n",
    "        'loguru',\n",
    "        'boto3',\n",
    "        'requests',\n",
    "        'pyyaml',\n",
    "        'cachetools',\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Initialize handlers with write permissions\n",
    "allow_write = args.allow_write\n",
    "allow_sensitive = args.allow_sensitive_data_access\n",
    "\n",
    "# Athena handlers\n",
    "athena_data_catalog_handler = AthenaDataCatalogHandler(allow_write=allow_write)\n",
    "athena_query_handler = AthenaQueryHandler(allow_write=allow_write, allow_sensitive_data_access=allow_sensitive)\n",
    "athena_workgroup_handler = AthenaWorkGroupHandler(allow_write=allow_write)\n",
    "\n",
    "# Common resource handler\n",
    "common_resource_handler = CommonResourceHandler(allow_write=allow_write)\n",
    "\n",
    "# EMR handlers\n",
    "emr_cluster_handler = EMREc2ClusterHandler(allow_write=allow_write)\n",
    "emr_instance_handler = EMREc2InstanceHandler(allow_write=allow_write)\n",
    "emr_steps_handler = EMREc2StepsHandler(allow_write=allow_write)\n",
    "\n",
    "# Glue handlers\n",
    "crawler_handler = CrawlerHandler(allow_write=allow_write)\n",
    "glue_data_catalog_handler = GlueDataCatalogHandler(allow_write=allow_write)\n",
    "glue_commons_handler = GlueCommonsHandler(allow_write=allow_write)\n",
    "glue_etl_handler = GlueEtlJobsHandler(allow_write=allow_write)\n",
    "glue_sessions_handler = GlueInteractiveSessionsHandler(allow_write=allow_write, allow_sensitive_data_access=allow_sensitive)\n",
    "glue_workflow_handler = GlueWorkflowAndTriggerHandler(allow_write=allow_write)\n",
    "\n",
    "# Register all tools from handlers\n",
    "# Athena tools\n",
    "mcp.tool(name='manage_aws_athena_data_catalogs')(athena_data_catalog_handler.manage_aws_athena_data_catalogs)\n",
    "mcp.tool(name='manage_aws_athena_databases_and_tables')(athena_data_catalog_handler.manage_aws_athena_databases_and_tables)\n",
    "mcp.tool(name='manage_aws_athena_query_executions')(athena_query_handler.manage_aws_athena_query_executions)\n",
    "mcp.tool(name='manage_aws_athena_named_queries')(athena_query_handler.manage_aws_athena_named_queries)\n",
    "mcp.tool(name='manage_aws_athena_workgroups')(athena_workgroup_handler.manage_aws_athena_workgroups)\n",
    "\n",
    "# Common resource tools\n",
    "mcp.tool(name='add_inline_policy')(common_resource_handler.add_inline_policy)\n",
    "mcp.tool(name='get_policies_for_role')(common_resource_handler.get_policies_for_role)\n",
    "mcp.tool(name='create_data_processing_role')(common_resource_handler.create_data_processing_role)\n",
    "mcp.tool(name='get_roles_for_service')(common_resource_handler.get_roles_for_service)\n",
    "mcp.tool(name='list_s3_buckets')(common_resource_handler.list_s3_buckets)\n",
    "mcp.tool(name='upload_to_s3')(common_resource_handler.upload_to_s3)\n",
    "mcp.tool(name='analyze_s3_usage_for_data_processing')(common_resource_handler.analyze_s3_usage_for_data_processing)\n",
    "\n",
    "# EMR tools\n",
    "mcp.tool(name='manage_aws_emr_clusters')(emr_cluster_handler.manage_aws_emr_clusters)\n",
    "mcp.tool(name='manage_aws_emr_ec2_instances')(emr_instance_handler.manage_aws_emr_ec2_instances)\n",
    "mcp.tool(name='manage_aws_emr_ec2_steps')(emr_steps_handler.manage_aws_emr_ec2_steps)\n",
    "\n",
    "# Glue tools\n",
    "mcp.tool(name='manage_aws_glue_crawlers')(crawler_handler.manage_aws_glue_crawlers)\n",
    "mcp.tool(name='manage_aws_glue_classifiers')(crawler_handler.manage_aws_glue_classifiers)\n",
    "mcp.tool(name='manage_aws_glue_crawler_management')(crawler_handler.manage_aws_glue_crawler_management)\n",
    "mcp.tool(name='manage_aws_glue_databases')(glue_data_catalog_handler.manage_aws_glue_databases)\n",
    "mcp.tool(name='manage_aws_glue_tables')(glue_data_catalog_handler.manage_aws_glue_tables)\n",
    "mcp.tool(name='manage_aws_glue_connections')(glue_data_catalog_handler.manage_aws_glue_connections)\n",
    "mcp.tool(name='manage_aws_glue_partitions')(glue_data_catalog_handler.manage_aws_glue_partitions)\n",
    "mcp.tool(name='manage_aws_glue_catalog')(glue_data_catalog_handler.manage_aws_glue_catalog)\n",
    "mcp.tool(name='manage_aws_glue_usage_profiles')(glue_commons_handler.manage_aws_glue_usage_profiles)\n",
    "mcp.tool(name='manage_aws_glue_security_configurations')(glue_commons_handler.manage_aws_glue_security_configurations)\n",
    "mcp.tool(name='manage_aws_glue_encryption')(glue_commons_handler.manage_aws_glue_encryption)\n",
    "mcp.tool(name='manage_aws_glue_resource_policies')(glue_commons_handler.manage_aws_glue_resource_policies)\n",
    "mcp.tool(name='manage_aws_glue_jobs')(glue_etl_handler.manage_aws_glue_jobs)\n",
    "mcp.tool(name='manage_aws_glue_sessions')(glue_sessions_handler.manage_aws_glue_sessions)\n",
    "mcp.tool(name='manage_aws_glue_statements')(glue_sessions_handler.manage_aws_glue_statements)\n",
    "mcp.tool(name='manage_aws_glue_workflows')(glue_workflow_handler.manage_aws_glue_workflows)\n",
    "mcp.tool(name='manage_aws_glue_triggers')(glue_workflow_handler.manage_aws_glue_triggers)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    write_mode = \"with write access\" if args.allow_write else \"in read-only mode\"\n",
    "    sensitive_mode = \" and sensitive data access\" if args.allow_sensitive_data_access else \"\"\n",
    "    print(f\"Starting AWS Data Processing MCP server {write_mode}{sensitive_mode} on http://0.0.0.0:8000\")\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Local Test Client\n",
    "\n",
    "The `mcp-client.py` creates a simple test client that:\n",
    "\n",
    "- Connects to the local MCP server at `http://0.0.0.0:8000/mcp`\n",
    "- Lists all available tools\n",
    "- Provides basic connectivity testing\n",
    "\n",
    "This client helps verify that your MCP server is running correctly before deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp-client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp-client.py\n",
    "#!/usr/bin/env python3\n",
    "import asyncio\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "async def test_server():\n",
    "    mcp_url = \"http://0.0.0.0:8000/mcp\"\n",
    "    \n",
    "    try:\n",
    "        async with streamablehttp_client(mcp_url, {}, terminate_on_close=False) as (\n",
    "            read_stream, write_stream, _\n",
    "        ):\n",
    "            async with ClientSession(read_stream, write_stream) as session:\n",
    "                await session.initialize()\n",
    "                \n",
    "                tool_result = await session.list_tools()\n",
    "                print(f\"Found {len(tool_result.tools)} tools:\")\n",
    "                \n",
    "                # Group tools by service\n",
    "                glue_tools = [t.name for t in tool_result.tools if 'glue' in t.name]\n",
    "                emr_tools = [t.name for t in tool_result.tools if 'emr' in t.name]\n",
    "                athena_tools = [t.name for t in tool_result.tools if 'athena' in t.name]\n",
    "                common_tools = [t.name for t in tool_result.tools if t.name not in glue_tools + emr_tools + athena_tools]\n",
    "                \n",
    "                print(f\"\\nAWS Glue tools ({len(glue_tools)}):\")\n",
    "                for tool in glue_tools:\n",
    "                    print(f\"  - {tool}\")\n",
    "                    \n",
    "                print(f\"\\nAmazon EMR tools ({len(emr_tools)}):\")\n",
    "                for tool in emr_tools:\n",
    "                    print(f\"  - {tool}\")\n",
    "                    \n",
    "                print(f\"\\nAmazon Athena tools ({len(athena_tools)}):\")\n",
    "                for tool in athena_tools:\n",
    "                    print(f\"  - {tool}\")\n",
    "                    \n",
    "                print(f\"\\nCommon resource tools ({len(common_tools)}):\")\n",
    "                for tool in common_tools:\n",
    "                    print(f\"  - {tool}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(test_server())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Local Testing Instructions\n",
    "\n",
    "To test your AWS Data Processing MCP server locally:\n",
    "\n",
    "1. **Terminal 1**: Start the MCP server\n",
    "   ```bash\n",
    "   python mcp-server.py --allow-write --allow-sensitive-data-access\n",
    "   ```\n",
    "   Expected output: `Starting AWS Data Processing MCP server with write access and sensitive data access on http://0.0.0.0:8000`\n",
    "   \n",
    "2. **Terminal 2**: Run the test client\n",
    "   ```bash\n",
    "   python mcp-client.py\n",
    "   ```\n",
    "   Expected output: `Found 25+ tools:` followed by categorized tool lists\n",
    "\n",
    "**Note**: Local testing requires AWS credentials with appropriate permissions for Glue, EMR, and Athena services. The server will start but tools may fail without proper AWS access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Amazon Cognito Authentication Setup\n",
    "\n",
    "AgentCore Runtime requires JWT-based authentication. We'll use Amazon Cognito to provide bearer tokens for accessing our deployed MCP server.\n",
    "\n",
    "The `utils.py` file contains helper functions:\n",
    "- `get_cognito_pool_info()`: Retrieves configuration from an existing Cognito User Pool\n",
    "- `setup_cognito_user_pool()`: Creates a new User Pool if needed\n",
    "- `create_agentcore_role()`: Creates the necessary IAM role with proper permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Cognito user pool info for pool id: eu-central-1_PaVtjk8dt in region: eu-central-1\n",
      "Setting up Amazon Cognito user pool...\n",
      "Using client ID: 4rit5a00iqft9ak8sl5hb28sr\n",
      "Making OAuth request to: https://mcp-registry-241533163649-mcp-gateway-registry.auth.eu-central-1.amazoncognito.com/oauth2/token\n",
      "✅ Successfully obtained bearer token via OAuth client credentials\n",
      "Pool id: eu-central-1_PaVtjk8dt\n",
      "Discovery URL: https://cognito-idp.eu-central-1.amazonaws.com/eu-central-1_PaVtjk8dt/.well-known/openid-configuration\n",
      "Client ID: 4rit5a00iqft9ak8sl5hb28sr\n",
      "Bearer Token: eyJraWQiOiJYZ1wvblZQWmtZeEtLM3ZicHBPRVQ2cUVYZUZLdE12QkVcLzVyWjJGK3ZoZWs9IiwiYWxnIjoiUlMyNTYifQ.eyJzdWIiOiI0cml0NWEwMGlxZnQ5YWs4c2w1aGIyOHNyIiwidG9rZW5fdXNlIjoiYWNjZXNzIiwic2NvcGUiOiJtY3AtcmVnaXN0cnlcL3JlYWQgbWNwLXJlZ2lzdHJ5XC93cml0ZSIsImF1dGhfdGltZSI6MTc1NzUzOTQ2NywiaXNzIjoiaHR0cHM6XC9cL2NvZ25pdG8taWRwLmV1LWNlbnRyYWwtMS5hbWF6b25hd3MuY29tXC9ldS1jZW50cmFsLTFfUGFWdGprOGR0IiwiZXhwIjoxNzU3NTQzMDY3LCJpYXQiOjE3NTc1Mzk0NjcsInZlcnNpb24iOjIsImp0aSI6ImI0ODU4ODMwLWNhMGUtNDViNi1hNmMwLWVjODkwZTNjNDUyNSIsImNsaWVudF9pZCI6IjRyaXQ1YTAwaXFmdDlhazhzbDVoYjI4c3IifQ.SplUtK0_Hoxn6HTwFsVVeuBGG3uJHH6b-zV6xFQ7ykp2h-W6wEwN5r_QA2aMGgoThPpFa3K5zd2RwdxGFYrC3Lr3pCZPmtHDYELICEIb6K4dphBbX7w5-V6bqsaUXw_yNvUrjx4EgbWokbbDnY8rd_qxGyPZ74h86UwhuWvgCu11SQ1rFN370JUpy16MSOSSxLaxWgF2CJO5Yr2JHJI_XI7126Np7tbSFml2EpSsYUZJude5_B_tbjNQDrilaVsvWzWtVEcnfWyCdhy_rcLVNV4bdBzkb5UpAVjQMP4bBugqY-yLNYHm3_NM2MTfYh6eBn6qkcryQRWEguaqpU-KmA\n",
      "Cognito setup completed ✓\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from utils import get_cognito_pool_info, create_agentcore_role\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pool_id = os.getenv('COGNITO_POOL_ID', 'us-east-1_XXXXX')\n",
    "region = os.getenv('COGNITO_REGION', 'us-east-1')\n",
    "    \n",
    "print(f\"Get Cognito user pool info for pool id: {pool_id} in region: {region}\")\n",
    "\n",
    "print(\"Setting up Amazon Cognito user pool...\")\n",
    "cognito_config = get_cognito_pool_info(pool_id, region)\n",
    "print(\"Cognito setup completed ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tool_name = \"dataprocessing_mcp_server\"  # Fixed: Remove 'aws_' prefix to meet validation rules\n",
    "additional_managed_policies = [\n",
    "    'AWSGlueConsoleFullAccess',  # Fixed: Use console access instead of service role\n",
    "    'AmazonS3FullAccess', \n",
    "    'AmazonEMRFullAccessPolicy_v2',\n",
    "    'AmazonAthenaFullAccess'\n",
    "]\n",
    "print(f\"Creating IAM role for {tool_name}...\")\n",
    "agentcore_iam_role = create_agentcore_role(\n",
    "    agent_name=tool_name, \n",
    "    managed_policies=additional_managed_policies\n",
    ")\n",
    "print(f\"IAM role created ✓\")\n",
    "print(f\"Role ARN: {agentcore_iam_role['Role']['Arn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating IAM role for dataproc_mcp_ibcv2...\n",
      "attaching inline role policy agentcore-dataproc_mcp_ibcv2-role\n",
      "Attaching 4 managed policies...\n",
      "Attaching managed policy: AWSGlueConsoleFullAccess\n",
      "✅ Successfully attached AWSGlueConsoleFullAccess\n",
      "Attaching managed policy: AmazonS3FullAccess\n",
      "✅ Successfully attached AmazonS3FullAccess\n",
      "Attaching managed policy: AmazonEMRFullAccessPolicy_v2\n",
      "✅ Successfully attached AmazonEMRFullAccessPolicy_v2\n",
      "Attaching managed policy: AmazonAthenaFullAccess\n",
      "✅ Successfully attached AmazonAthenaFullAccess\n",
      "IAM role created ✓\n",
      "Role ARN: arn:aws:iam::241533163649:role/agentcore-dataproc_mcp_ibcv2-role\n"
     ]
    }
   ],
   "source": [
    "tool_name = \"dataproc_mcp_ibcv2\"\n",
    "additional_managed_policies = [\n",
    "    'AWSGlueConsoleFullAccess',\n",
    "    'AmazonS3FullAccess', \n",
    "    'AmazonEMRFullAccessPolicy_v2',\n",
    "    'AmazonAthenaFullAccess'\n",
    "]\n",
    "print(f\"Creating IAM role for {tool_name}...\")\n",
    "agentcore_iam_role = create_agentcore_role(\n",
    "    agent_name=tool_name, \n",
    "    managed_policies=additional_managed_policies\n",
    ")\n",
    "print(f\"IAM role created ✓\")\n",
    "print(f\"Role ARN: {agentcore_iam_role['Role']['Arn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating trust policy for role: agentcore-dataproc_mcp_ibcv2-role\n",
      "Account ID: 241533163649\n",
      "Region: eu-central-1\n",
      "✅ Trust policy updated successfully\n",
      "\n",
      "✅ Role verification:\n",
      "  - Role ARN: arn:aws:iam::241533163649:role/agentcore-dataproc_mcp_ibcv2-role\n",
      "  - Trust policy updated: Yes\n",
      "\n",
      "⏳ Waiting 30 seconds for IAM changes to propagate...\n",
      "✅ IAM propagation wait completed\n",
      "\n",
      "✅ Role is now ready. You can retry the launch operation.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role_name = 'agentcore-dataproc_mcp_ibcv2-role'  # Updated for new tool name\n",
    "\n",
    "# Define the correct trust policy for bedrock-agentcore\n",
    "trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AssumeRolePolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"bedrock-agentcore.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": account_id\n",
    "                },\n",
    "                \"ArnLike\": {\n",
    "                    \"aws:SourceArn\": f\"arn:aws:bedrock-agentcore:{region}:{account_id}:*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Updating trust policy for role: {role_name}\")\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Region: {region}\")\n",
    "\n",
    "try:\n",
    "    # Update the assume role policy\n",
    "    iam_client.update_assume_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyDocument=json.dumps(trust_policy)\n",
    "    )\n",
    "    print(\"✅ Trust policy updated successfully\")\n",
    "    \n",
    "    # Verify the update\n",
    "    role_info = iam_client.get_role(RoleName=role_name)\n",
    "    print(\"\\n✅ Role verification:\")\n",
    "    print(f\"  - Role ARN: {role_info['Role']['Arn']}\")\n",
    "    print(f\"  - Trust policy updated: Yes\")\n",
    "    \n",
    "    # Wait for propagation\n",
    "    import time\n",
    "    print(\"\\n⏳ Waiting 30 seconds for IAM changes to propagate...\")\n",
    "    time.sleep(30)\n",
    "    print(\"✅ IAM propagation wait completed\")\n",
    "    \n",
    "    print(\"\\n✅ Role is now ready. You can retry the launch operation.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error updating trust policy: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ECR permissions to role: agentcore-dataproc_mcp_ibcv2-role\n",
      "Account ID: 241533163649\n",
      "Region: eu-central-1\n",
      "✅ ECR permissions added successfully\n",
      "\n",
      "📋 Inline policies attached to role:\n",
      "  - AgentCorePolicy\n",
      "  - ECRAccessPolicy\n",
      "\n",
      "⏳ Waiting 20 seconds for IAM changes to propagate...\n",
      "✅ IAM propagation wait completed\n",
      "\n",
      "✅ ECR permissions are now properly configured. You can retry the launch operation.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role_name = 'agentcore-dataproc_mcp_ibcv2-role'  # Updated for new tool name\n",
    "\n",
    "# Define the corrected ECR policy\n",
    "ecr_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"ECRAuthToken\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"ecr:GetAuthorizationToken\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"ECRImageAccess\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"ecr:BatchGetImage\",\n",
    "                \"ecr:GetDownloadUrlForLayer\",\n",
    "                \"ecr:BatchCheckLayerAvailability\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:ecr:{region}:{account_id}:repository/bedrock-agentcore-dataprocessing_mcp_server\",\n",
    "                f\"arn:aws:ecr:{region}:{account_id}:repository/bedrock-agentcore-dataprocessing_mcp_server/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Adding ECR permissions to role: {role_name}\")\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Region: {region}\")\n",
    "\n",
    "try:\n",
    "    # Add the ECR policy as an inline policy\n",
    "    iam_client.put_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyName='ECRAccessPolicy',\n",
    "        PolicyDocument=json.dumps(ecr_policy)\n",
    "    )\n",
    "    print(\"✅ ECR permissions added successfully\")\n",
    "    \n",
    "    # List all policies attached to the role\n",
    "    inline_policies = iam_client.list_role_policies(RoleName=role_name)\n",
    "    print(f\"\\n📋 Inline policies attached to role:\")\n",
    "    for policy in inline_policies['PolicyNames']:\n",
    "        print(f\"  - {policy}\")\n",
    "    \n",
    "    # Wait for propagation\n",
    "    import time\n",
    "    print(\"\\n⏳ Waiting 20 seconds for IAM changes to propagate...\")\n",
    "    time.sleep(20)\n",
    "    print(\"✅ IAM propagation wait completed\")\n",
    "    \n",
    "    print(\"\\n✅ ECR permissions are now properly configured. You can retry the launch operation.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error adding ECR permissions: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AgentCore Runtime Configuration\n",
    "\n",
    "Configure the AgentCore Runtime deployment using the Bedrock AgentCore Starter Toolkit:\n",
    "\n",
    "### Configuration Parameters\n",
    "- **Entrypoint**: `mcp-server.py` (our FastMCP wrapper with handler registration)\n",
    "- **Execution Role**: The IAM role created above with data processing permissions\n",
    "- **Requirements**: `dataprocessing-requirements.txt` with all dependencies\n",
    "- **Protocol**: MCP (Model Context Protocol)\n",
    "- **Authentication**: Custom JWT authorizer with Cognito\n",
    "\n",
    "### Auto-Generated Resources\n",
    "- Dockerfile optimized for the MCP server with data processing dependencies\n",
    "- Amazon ECR repository for container storage\n",
    "- AgentCore Runtime configuration with environment variables\n",
    "\n",
    "The configuration validates that all required files exist before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrypoint parsed: file=/Users/dohtem/Downloads/claude/ibc2025-acme-corp-bedrockagentcore-chatbot/aws-mcp-server-agentcore/mcp-server.py, bedrock_agentcore_name=mcp-server\n",
      "Configuring BedrockAgentCore agent: dataproc_mcp_ibcv2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS region: eu-central-1\n",
      "All required files found ✓\n",
      "Configuring AgentCore Runtime...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated Dockerfile: /Users/dohtem/Downloads/claude/ibc2025-acme-corp-bedrockagentcore-chatbot/aws-mcp-server-agentcore/Dockerfile\n",
      "Generated .dockerignore: /Users/dohtem/Downloads/claude/ibc2025-acme-corp-bedrockagentcore-chatbot/aws-mcp-server-agentcore/.dockerignore\n",
      "Changing default agent from 'dataproc_mcp_ibc' to 'dataproc_mcp_ibcv2'\n",
      "Bedrock AgentCore configured: /Users/dohtem/Downloads/claude/ibc2025-acme-corp-bedrockagentcore-chatbot/aws-mcp-server-agentcore/.bedrock_agentcore.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration completed ✓\n"
     ]
    }
   ],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "import time\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "print(f\"Using AWS region: {region}\")\n",
    "\n",
    "required_files = ['mcp-server.py', 'dataprocessing-requirements.txt']\n",
    "for file in required_files:\n",
    "    if not os.path.exists(file):\n",
    "        raise FileNotFoundError(f\"Required file {file} not found\")\n",
    "print(\"All required files found ✓\")\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "auth_config = {\n",
    "    \"customJWTAuthorizer\": {\n",
    "        \"allowedClients\": [\n",
    "            cognito_config['client_id']\n",
    "        ],\n",
    "        \"discoveryUrl\": cognito_config['discovery_url'],\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Configuring AgentCore Runtime...\")\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"mcp-server.py\",\n",
    "    execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"dataprocessing-requirements.txt\",\n",
    "    region=region,\n",
    "    authorizer_configuration=auth_config,\n",
    "    protocol=\"MCP\",\n",
    "    agent_name=tool_name\n",
    ")\n",
    "print(\"Configuration completed ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deployment to AgentCore Runtime\n",
    "\n",
    "Launch the MCP server to AgentCore Runtime. This process:\n",
    "\n",
    "### Build and Deploy Steps\n",
    "1. **Container Build**: Creates Docker image from the generated Dockerfile with data processing dependencies\n",
    "2. **ECR Push**: Uploads the container to Amazon ECR\n",
    "3. **Runtime Creation**: Deploys the AgentCore Runtime with comprehensive permissions\n",
    "4. **Service Registration**: Registers the MCP server endpoint with 25+ data processing tools\n",
    "\n",
    "### Expected Outputs\n",
    "- Agent ARN: Unique identifier for the deployed runtime\n",
    "- Agent ID: Short identifier for management operations\n",
    "- ECR URI: Container image location\n",
    "\n",
    "**Note**: This process typically takes 8-12 minutes due to the comprehensive dependencies and handler registrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀 CodeBuild mode: building in cloud (RECOMMENDED - DEFAULT)\n",
      "   • Build ARM64 containers in the cloud with CodeBuild\n",
      "   • No local Docker required\n",
      "💡 Available deployment modes:\n",
      "   • runtime.launch()                           → CodeBuild (current)\n",
      "   • runtime.launch(local=True)                 → Local development\n",
      "   • runtime.launch(local_build=True)           → Local build + cloud deploy (NEW)\n",
      "Starting CodeBuild ARM64 deployment for agent 'dataproc_mcp_ibcv2' to account 241533163649 (eu-central-1)\n",
      "Starting CodeBuild ARM64 deployment for agent 'dataproc_mcp_ibcv2' to account 241533163649 (eu-central-1)\n",
      "Setting up AWS resources (ECR repository, execution roles)...\n",
      "Getting or creating ECR repository for agent: dataproc_mcp_ibcv2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching MCP server to AgentCore Runtime...\n",
      "This may take several minutes due to data processing dependencies...\n",
      "Repository doesn't exist, creating new ECR repository: bedrock-agentcore-dataproc_mcp_ibcv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✅ ECR repository available: 241533163649.dkr.ecr.eu-central-1.amazonaws.com/bedrock-agentcore-dataproc_mcp_ibcv2\n",
      "Using execution role from config: arn:aws:iam::241533163649:role/agentcore-dataproc_mcp_ibcv2-role\n",
      "✅ Execution role validation passed: arn:aws:iam::241533163649:role/agentcore-dataproc_mcp_ibcv2-role\n",
      "Preparing CodeBuild project and uploading source...\n",
      "Getting or creating CodeBuild execution role for agent: dataproc_mcp_ibcv2\n",
      "Role name: AmazonBedrockAgentCoreSDKCodeBuild-eu-central-1-183e5f3ed3\n",
      "CodeBuild role doesn't exist, creating new role: AmazonBedrockAgentCoreSDKCodeBuild-eu-central-1-183e5f3ed3\n",
      "Creating IAM role: AmazonBedrockAgentCoreSDKCodeBuild-eu-central-1-183e5f3ed3\n",
      "✓ Role created: arn:aws:iam::241533163649:role/AmazonBedrockAgentCoreSDKCodeBuild-eu-central-1-183e5f3ed3\n",
      "Attaching inline policy: CodeBuildExecutionPolicy to role: AmazonBedrockAgentCoreSDKCodeBuild-eu-central-1-183e5f3ed3\n",
      "✓ Policy attached: CodeBuildExecutionPolicy\n",
      "Waiting for IAM role propagation...\n",
      "CodeBuild execution role creation complete: arn:aws:iam::241533163649:role/AmazonBedrockAgentCoreSDKCodeBuild-eu-central-1-183e5f3ed3\n",
      "Using .dockerignore with 44 patterns\n",
      "Uploaded source to S3: dataproc_mcp_ibcv2/20250910-212658.zip\n",
      "Created CodeBuild project: bedrock-agentcore-dataproc_mcp_ibcv2-builder\n",
      "Starting CodeBuild build (this may take several minutes)...\n",
      "Starting CodeBuild monitoring...\n",
      "🔄 QUEUED started (total: 0s)\n",
      "✅ QUEUED completed in 5.1s\n",
      "🔄 PROVISIONING started (total: 5s)\n",
      "✅ PROVISIONING completed in 5.1s\n",
      "🔄 DOWNLOAD_SOURCE started (total: 10s)\n",
      "✅ DOWNLOAD_SOURCE completed in 5.1s\n",
      "🔄 PRE_BUILD started (total: 16s)\n",
      "✅ PRE_BUILD completed in 10.3s\n",
      "🔄 BUILD started (total: 26s)\n",
      "✅ BUILD completed in 41.0s\n",
      "🔄 POST_BUILD started (total: 67s)\n",
      "✅ POST_BUILD completed in 5.1s\n",
      "🔄 COMPLETED started (total: 72s)\n",
      "✅ COMPLETED completed in 0.0s\n",
      "🎉 CodeBuild completed successfully in 1m 11s\n",
      "CodeBuild completed successfully\n",
      "✅ CodeBuild project configuration saved\n",
      "Deploying to Bedrock AgentCore...\n",
      "✅ Agent created/updated: arn:aws:bedrock-agentcore:eu-central-1:241533163649:runtime/dataproc_mcp_ibcv2-1MQhok269k\n",
      "Polling for endpoint to be ready...\n",
      "Agent endpoint: arn:aws:bedrock-agentcore:eu-central-1:241533163649:runtime/dataproc_mcp_ibcv2-1MQhok269k/runtime-endpoint/DEFAULT\n",
      "Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:eu-central-1:241533163649:runtime/dataproc_mcp_ibcv2-1MQhok269k\n",
      "Built with CodeBuild: bedrock-agentcore-dataproc_mcp_ibcv2-builder:dc0b2dea-fa29-491d-a3bb-233911587732\n",
      "Deployed to cloud: arn:aws:bedrock-agentcore:eu-central-1:241533163649:runtime/dataproc_mcp_ibcv2-1MQhok269k\n",
      "ECR image: 241533163649.dkr.ecr.eu-central-1.amazonaws.com/bedrock-agentcore-dataproc_mcp_ibcv2\n",
      "🔍 Agent logs available at:\n",
      "   /aws/bedrock-agentcore/runtimes/dataproc_mcp_ibcv2-1MQhok269k-DEFAULT\n",
      "   /aws/bedrock-agentcore/runtimes/dataproc_mcp_ibcv2-1MQhok269k-DEFAULT/runtime-logs\n",
      "💡 Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/dataproc_mcp_ibcv2-1MQhok269k-DEFAULT --follow\n",
      "💡 Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/dataproc_mcp_ibcv2-1MQhok269k-DEFAULT --since 1h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch completed ✓\n",
      "Agent ARN: arn:aws:bedrock-agentcore:eu-central-1:241533163649:runtime/dataproc_mcp_ibcv2-1MQhok269k\n",
      "Agent ID: dataproc_mcp_ibcv2-1MQhok269k\n"
     ]
    }
   ],
   "source": [
    "print(\"Launching MCP server to AgentCore Runtime...\")\n",
    "print(\"This may take several minutes due to data processing dependencies...\")\n",
    "launch_result = agentcore_runtime.launch()\n",
    "print(\"Launch completed ✓\")\n",
    "print(f\"Agent ARN: {launch_result.agent_arn}\")\n",
    "print(f\"Agent ID: {launch_result.agent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Runtime Status Monitoring\n",
    "\n",
    "Monitor the AgentCore Runtime deployment status:\n",
    "\n",
    "### Status States\n",
    "- **CREATING**: Runtime is being deployed\n",
    "- **READY**: Runtime is operational and ready to serve requests\n",
    "- **CREATE_FAILED**: Deployment failed\n",
    "- **UPDATE_FAILED**: Update operation failed\n",
    "- **DELETE_FAILED**: Deletion operation failed\n",
    "\n",
    "The monitoring loop checks status every 10 seconds until reaching a terminal state. Only proceed to testing when status is **READY**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieved Bedrock AgentCore status for: dataproc_mcp_ibcv2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial status: READY\n",
      "✓ AgentCore Runtime is READY!\n"
     ]
    }
   ],
   "source": [
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "print(f\"Initial status: {status}\")\n",
    "\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    print(f\"Status: {status} - waiting...\")\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "\n",
    "if status == 'READY':\n",
    "    print(\"✓ AgentCore Runtime is READY!\")\n",
    "else:\n",
    "    print(f\"⚠ AgentCore Runtime status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cognito credentials updated in Secrets Manager\n",
      "✓ Agent ARN stored in Parameter Store\n",
      "\n",
      "Configuration stored successfully!\n",
      "Agent ARN: arn:aws:bedrock-agentcore:eu-central-1:241533163649:runtime/dataproc_mcp_ibcv2-1MQhok269k\n",
      "Parameter path: /mcp/aws_dataprocessing_server-ibc/runtime/agent_arn\n",
      "Secret path: mcp/aws_dataprocessing_server-ibc/cognito/credentials\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "ssm_client = boto3.client('ssm', region_name=region)\n",
    "secrets_client = boto3.client('secretsmanager', region_name=region)\n",
    "\n",
    "# Store Cognito credentials in Secrets Manager with the actual path used in the client\n",
    "try:\n",
    "    cognito_credentials_response = secrets_client.create_secret(\n",
    "        Name='mcp/aws_dataprocessing_server-ibc/cognito/credentials',\n",
    "        Description='Cognito credentials for AWS Data Processing MCP server',\n",
    "        SecretString=json.dumps(cognito_config)\n",
    "    )\n",
    "    print(\"✓ Cognito credentials stored in Secrets Manager\")\n",
    "except secrets_client.exceptions.ResourceExistsException:\n",
    "    secrets_client.update_secret(\n",
    "        SecretId='mcp/aws_dataprocessing_server-ibc/cognito/credentials',\n",
    "        SecretString=json.dumps(cognito_config)\n",
    "    )\n",
    "    print(\"✓ Cognito credentials updated in Secrets Manager\")\n",
    "\n",
    "# Store the actual agent ARN in Parameter Store\n",
    "agent_arn_response = ssm_client.put_parameter(\n",
    "    Name='/mcp/aws_dataprocessing_server-ibc/runtime/agent_arn',\n",
    "    Value=launch_result.agent_arn,\n",
    "    Type='String',\n",
    "    Description='Agent ARN for AWS Data Processing MCP server',\n",
    "    Overwrite=True\n",
    ")\n",
    "print(\"✓ Agent ARN stored in Parameter Store\")\n",
    "\n",
    "print(\"\\nConfiguration stored successfully!\")\n",
    "print(f\"Agent ARN: {launch_result.agent_arn}\")\n",
    "print(f\"Parameter path: /mcp/aws_dataprocessing_server-ibc/runtime/agent_arn\")\n",
    "print(f\"Secret path: mcp/aws_dataprocessing_server-ibc/cognito/credentials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_client_remote.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_client_remote.py\n",
    "import asyncio\n",
    "import boto3\n",
    "import json\n",
    "import sys\n",
    "from boto3.session import Session\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "async def main():\n",
    "    boto_session = Session()\n",
    "    region = boto_session.region_name\n",
    "    \n",
    "    print(f\"Using AWS region: {region}\")\n",
    "    \n",
    "    try:\n",
    "        ssm_client = boto3.client('ssm', region_name=region)\n",
    "        agent_arn_response = ssm_client.get_parameter(Name='/mcp/aws_dataprocessing_server-ibc/runtime/agent_arn')\n",
    "        agent_arn = agent_arn_response['Parameter']['Value']\n",
    "        print(f\"Retrieved Agent ARN: {agent_arn}\")\n",
    "\n",
    "        secrets_client = boto3.client('secretsmanager', region_name=region)\n",
    "        response = secrets_client.get_secret_value(SecretId='mcp/aws_dataprocessing_server-ibc/cognito/credentials')\n",
    "        secret_value = response['SecretString']\n",
    "        parsed_secret = json.loads(secret_value)\n",
    "        bearer_token = parsed_secret['bearer_token']\n",
    "        print(\"✓ Retrieved bearer token from Secrets Manager\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving credentials: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if not agent_arn or not bearer_token:\n",
    "        print(\"Error: AGENT_ARN or BEARER_TOKEN not retrieved properly\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    encoded_arn = agent_arn.replace(':', '%3A').replace('/', '%2F')\n",
    "    mcp_url = f\"https://bedrock-agentcore.{region}.amazonaws.com/runtimes/{encoded_arn}/invocations?qualifier=DEFAULT\"\n",
    "    headers = {\n",
    "        \"authorization\": f\"Bearer {bearer_token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json, text/event-stream\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nConnecting to: {mcp_url}\")\n",
    "\n",
    "    try:\n",
    "        async with streamablehttp_client(mcp_url, headers, terminate_on_close=False) as (\n",
    "            read_stream,\n",
    "            write_stream,\n",
    "            _,\n",
    "        ):\n",
    "            async with ClientSession(read_stream, write_stream) as session:\n",
    "                print(\"\\n🔄 Initializing MCP session...\")\n",
    "                await session.initialize()\n",
    "                \n",
    "                tool_result = await session.list_tools()\n",
    "                \n",
    "                # Group tools by service\n",
    "                glue_tools = [tool for tool in tool_result.tools if 'glue' in tool.name]\n",
    "                emr_tools = [tool for tool in tool_result.tools if 'emr' in tool.name]\n",
    "                athena_tools = [tool for tool in tool_result.tools if 'athena' in tool.name]\n",
    "                common_tools = [tool for tool in tool_result.tools if tool not in glue_tools + emr_tools + athena_tools]\n",
    "                \n",
    "                print(\"\\n📋 Available MCP Tools:\")\n",
    "                print(\"=\" * 60)\n",
    "                \n",
    "                print(f\"\\n🔧 AWS Glue Tools ({len(glue_tools)} tools):\")\n",
    "                for tool in glue_tools:\n",
    "                    print(f\"   • {tool.name}\")\n",
    "                    \n",
    "                print(f\"\\n🚀 Amazon EMR Tools ({len(emr_tools)} tools):\")\n",
    "                for tool in emr_tools:\n",
    "                    print(f\"   • {tool.name}\")\n",
    "                    \n",
    "                print(f\"\\n📊 Amazon Athena Tools ({len(athena_tools)} tools):\")\n",
    "                for tool in athena_tools:\n",
    "                    print(f\"   • {tool.name}\")\n",
    "                    \n",
    "                print(f\"\\n🛠️  Common Resource Tools ({len(common_tools)} tools):\")\n",
    "                for tool in common_tools:\n",
    "                    print(f\"   • {tool.name}\")\n",
    "                \n",
    "                print(f\"\\n✅ Successfully connected to MCP server!\")\n",
    "                print(f\"Found {len(tool_result.tools)} AWS Data Processing tools available.\")\n",
    "                print(f\"Server is ready for comprehensive data processing workflows across Glue, EMR, and Athena.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error connecting to MCP server: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing deployed MCP server...\n",
      "============================================================\n",
      "Using AWS region: eu-central-1\n",
      "Retrieved Agent ARN: arn:aws:bedrock-agentcore:eu-central-1:241533163649:runtime/dataproc_mcp_ibcv2-1MQhok269k\n",
      "✓ Retrieved bearer token from Secrets Manager\n",
      "\n",
      "Connecting to: https://bedrock-agentcore.eu-central-1.amazonaws.com/runtimes/arn%3Aaws%3Abedrock-agentcore%3Aeu-central-1%3A241533163649%3Aruntime%2Fdataproc_mcp_ibcv2-1MQhok269k/invocations?qualifier=DEFAULT\n",
      "\n",
      "🔄 Initializing MCP session...\n",
      "^C\n",
      "Error in sys.excepthook:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dohtem/Downloads/claude/ibc2025-acme-corp-bedrockagentcore-chatbot/aws-mcp-server-agentcore/.venv/lib/python3.10/site-packages/exceptiongroup/_formatting.py\", line 71, in exceptiongroup_excepthook\n",
      "    sys.stderr.write(\"\".join(traceback.format_exception(etype, value, tb)))\n",
      "KeyboardInterrupt\n",
      "\n",
      "Original exception was:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dohtem/Downloads/claude/ibc2025-acme-corp-bedrockagentcore-chatbot/aws-mcp-server-agentcore/mcp_client_remote.py\", line 93, in <module>\n",
      "    asyncio.run(main())\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 636, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1871, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/selectors.py\", line 562, in select\n",
      "    kev_list = self._selector.control(None, max_ev, timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing deployed MCP server...\")\n",
    "print(\"=\" * 60)\n",
    "!uv run python3 mcp_client_remote.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
